# Deep Learning Specialization Course Notes

This is the notes I took while studying the [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) course offered by [deeplearning.ai](https://www.deeplearning.ai/) on Coursera, mainly to track my learning progress and consolidate my understanding of the course, but also to organize the knowledge points and make it easy to check them at any time.

Introduction from the specialization page:

>In five courses, you will learn the foundations of Deep Learning, understand how to build neural networks, and learn how to lead successful machine learning projects. You will learn about Convolutional networks, RNNs, LSTM, Adam, Dropout, BatchNorm, Xavier/He initialization, and more. You will work on case studies from healthcare, autonomous driving, sign language reading, music generation, and natural language processing. You will master not only the theory, but also see how it is applied in industry. You will practice all these ideas in Python and in TensorFlow, which we will teach.

*The Specialization consists of five courses*:

- [Course 1: Neural Networks and Deep Learning](C1-Neural-Networks-and-Deep-Learning/readme.md)
  - [Week 1: Introduction to Deep Learning](C1-Neural-Networks-and-Deep-Learning/readme.md#week-1-introduction-to-deep-learning)
  - [Week 2: Neural Networks Basics](C1-Neural-Networks-and-Deep-Learning/readme.md#week-2-neural-networks-basics)
  - [Week 3: Shallow Neural Networks](C1-Neural-Networks-and-Deep-Learning/readme.md#week-3-shallow-neural-networks)
  - [Week 4: Deep Neural Networks](C1-Neural-Networks-and-Deep-Learning/readme.md#week-4-deep-neural-networks)
- [Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization](C2-Improving-Deep-Neural-Networks/readme.md)
  - [Week 1: Practical aspects of Deep Learning](C2-Improving-Deep-Neural-Networks/readme.md#week-1-practical-aspects-of-deep-learning)
  - [Week 2: Optimization algorithms](C2-Improving-Deep-Neural-Networks/readme.md#week-2-optimization-algorithms)
  - [Week 3: Hyperparameter tuning, Batch Normalization and Programming Frameworks](C2-Improving-Deep-Neural-Networks/readme.md#week-3-hyperparameter-tuning-batch-normalization-and-programming-frameworks)
- [Course 3: Structuring Machine Learning Projects](C3-Structuring-Machine-Learning-Projects/readme.md)
  - [Week 1: ML Strategy (1)](C3-Structuring-Machine-Learning-Projects/readme.md#week-1-ml-strategy-1)
  - [Week 2: ML Strategy (2)](C3-Structuring-Machine-Learning-Projects/readme.md#week-2-ml-strategy-2)
- [Course 4: Convolutional Neural Networks](C4-Convolutional-Neural-Networks/readme.md)
  - [Week 1: Foundations of Convolutional Neural Networks](C4-Convolutional-Neural-Networks/readme.md#week-1-foundations-of-convolutional-neural-networks)
  - [Week 2: Classic Networks](C4-Convolutional-Neural-Networks/readme.md#week-2-classic-networks)
  - Week 3
  - Week 4
- Course 5: Sequence Models

Some hand-drawn flowcharts by Andrew Ng are very important for the understanding of the algorithm process, so I reorganized them for easy viewing, such as:

![cnn-example](C4-Convolutional-Neural-Networks/img/nn-example.png)

For some of the more difficult concepts to understand, I've added some reference links. And I use a lot of tables to sort out concepts, which I think makes it easier to look up and compare.

Besides, math formulas are very important for learning, and using Latex can make them more clearly presented, but since GitHub markdown does not support direct display of math formulas, I have converted most of them to svg images using the [online formula editor](https://latex.codecogs.com/eqneditor/editor.php).
